{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get AUC of ensembled test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "DATA_PATH = os.getenv(\"DATA_PATH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get train and test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full labels\n",
    "labels = pl.read_parquet(f\"{DATA_PATH}/interim/labels.parquet\")\n",
    "\n",
    "# Train data of sybilscar (uses 600 previously defined samples)\n",
    "train_sybilscar = pl.read_parquet(f\"{DATA_PATH}/interim/train_labels.parquet\")\n",
    "\n",
    "# Train data for ml model\n",
    "test_sybilscar = labels.filter(~pl.col(\"fid\").is_in(train_sybilscar[\"fid\"]))\n",
    "train_ml = test_sybilscar.filter(pl.col(\"bot\")).sample(3000,seed=42)\n",
    "train_ml = pl.concat([train_sybilscar, train_ml])\n",
    "\n",
    "test_ml = labels.filter(~pl.col(\"fid\").is_in(train_ml[\"fid\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ml\n",
      " bot\n",
      "True     3300\n",
      "False     300\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "test_ml\n",
      " bot\n",
      "True     1332\n",
      "False     116\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "train_sybilscar\n",
      " bot\n",
      "False    300\n",
      "True     300\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "test_sybilscar\n",
      " bot\n",
      "True     4332\n",
      "False     116\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"train_ml\\n\",train_ml[\"bot\"].to_pandas().value_counts(),\"\\n\")\n",
    "print(\"test_ml\\n\",test_ml[\"bot\"].to_pandas().value_counts(),\"\\n\")\n",
    "print(\"train_sybilscar\\n\",train_sybilscar[\"bot\"].to_pandas().value_counts(),\"\\n\")\n",
    "print(\"test_sybilscar\\n\",test_sybilscar[\"bot\"].to_pandas().value_counts(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train ml model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import polars as pl\n",
    "from farcaster_sybil_detection.config.defaults import Config\n",
    "from farcaster_sybil_detection.services.detector import DetectorService\n",
    "from farcaster_sybil_detection.features.registry import FeatureRegistry\n",
    "from farcaster_sybil_detection.features.extractors.content_engagement_extractor import (\n",
    "    ContentEngagementExtractor,\n",
    ")\n",
    "from farcaster_sybil_detection.features.extractors.network_analysis_extractor import (\n",
    "    NetworkAnalysisExtractor,\n",
    ")\n",
    "from farcaster_sybil_detection.features.extractors.temporal_behavior_extractor import (\n",
    "    TemporalBehaviorExtractor,\n",
    ")\n",
    "from farcaster_sybil_detection.features.extractors.user_identity_extractor import (\n",
    "    UserIdentityExtractor,\n",
    ")\n",
    "\n",
    "pl.Config.set_streaming_chunk_size(1_000_000)\n",
    "pl.Config.set_fmt_str_lengths(50)\n",
    "\n",
    "config = Config(\n",
    "    data_path=Path(f\"{DATA_PATH}/raw\"),\n",
    "    checkpoint_dir=Path(f\"{DATA_PATH}/checkpoints\"),\n",
    "    model_dir=Path(f\"{DATA_PATH}/models\"),\n",
    ")\n",
    "\n",
    "registry = FeatureRegistry()\n",
    "\n",
    "# Register in any order - manager will figure out correct build order\n",
    "registry.register(\"user_identity\", UserIdentityExtractor)\n",
    "registry.register(\"network_analysis\", NetworkAnalysisExtractor)\n",
    "registry.register(\"temporal_behavior\", TemporalBehaviorExtractor)\n",
    "# registry.register(\"content_engagement\", ContentEngagementExtractor)\n",
    "# registry.register(\"reputation_meta\", ReputationMetaExtractor)\n",
    "\n",
    "detector = DetectorService(config, registry)\n",
    "\n",
    "metrics = detector.trainer.train(train_ml)\n",
    "print(\"Training Metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_output = []\n",
    "\n",
    "for fid in test_ml[\"fid\"].to_list():\n",
    "  try:\n",
    "    ml_output.append(detector.predict(fid)[\"probability\"])\n",
    "  except:\n",
    "    ml_output.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_443, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>fid</th><th>bot</th><th>ml_proba</th></tr><tr><td>i64</td><td>bool</td><td>f64</td></tr></thead><tbody><tr><td>11</td><td>false</td><td>0.05556</td></tr><tr><td>52</td><td>false</td><td>0.067287</td></tr><tr><td>55</td><td>false</td><td>0.057609</td></tr><tr><td>63</td><td>false</td><td>0.091361</td></tr><tr><td>64</td><td>false</td><td>0.053966</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>351522</td><td>true</td><td>0.985655</td></tr><tr><td>421493</td><td>true</td><td>0.949381</td></tr><tr><td>287794</td><td>true</td><td>0.985682</td></tr><tr><td>423036</td><td>true</td><td>0.98561</td></tr><tr><td>327500</td><td>true</td><td>0.98557</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_443, 3)\n",
       "┌────────┬───────┬──────────┐\n",
       "│ fid    ┆ bot   ┆ ml_proba │\n",
       "│ ---    ┆ ---   ┆ ---      │\n",
       "│ i64    ┆ bool  ┆ f64      │\n",
       "╞════════╪═══════╪══════════╡\n",
       "│ 11     ┆ false ┆ 0.05556  │\n",
       "│ 52     ┆ false ┆ 0.067287 │\n",
       "│ 55     ┆ false ┆ 0.057609 │\n",
       "│ 63     ┆ false ┆ 0.091361 │\n",
       "│ 64     ┆ false ┆ 0.053966 │\n",
       "│ …      ┆ …     ┆ …        │\n",
       "│ 351522 ┆ true  ┆ 0.985655 │\n",
       "│ 421493 ┆ true  ┆ 0.949381 │\n",
       "│ 287794 ┆ true  ┆ 0.985682 │\n",
       "│ 423036 ┆ true  ┆ 0.98561  │\n",
       "│ 327500 ┆ true  ┆ 0.98557  │\n",
       "└────────┴───────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml auc: 0.9899793732117905\n"
     ]
    }
   ],
   "source": [
    "ml_predictions = test_ml.with_columns(pl.Series(\"ml_proba\",ml_output).alias(\"ml_proba\"))\n",
    "ml_predictions = ml_predictions.filter(pl.col(\"ml_proba\").is_not_null())\n",
    "display(ml_predictions)\n",
    "\n",
    "ml_auc = roc_auc_score(\n",
    "  ml_predictions[\"bot\"].cast(pl.Int8).to_numpy(),\n",
    "  ml_predictions[f\"ml_proba\"]\n",
    ")\n",
    "\n",
    "print(\"ml auc:\",ml_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run SybilSCAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import asyncio\n",
    "import aiofiles\n",
    "import polars as pl\n",
    "import time\n",
    "import logging\n",
    "\n",
    "class FarcasterBaseProcessor:\n",
    "    def __init__(self):\n",
    "        self.data_path = f\"{DATA_PATH}/raw\"\n",
    "        self.persisted_data_path = f\"{DATA_PATH}/interim\"\n",
    "\n",
    "    async def get_latest_parquet_file(self, file_pattern):\n",
    "        \"\"\"Gets the latest parquet file matching a pattern.\"\"\"\n",
    "        parquet_files = await asyncio.to_thread(\n",
    "            glob.glob, os.path.join(self.data_path, file_pattern)\n",
    "        )\n",
    "        if not parquet_files:\n",
    "            raise FileNotFoundError(f\"No files found matching pattern: {file_pattern}\")\n",
    "        parquet_files.sort()\n",
    "        return parquet_files[-1]\n",
    "\n",
    "    def get_links_lazy_df(self, file_path):\n",
    "        \"\"\"Returns a lazy DataFrame for the given parquet file.\"\"\"\n",
    "        return pl.scan_parquet(file_path)\n",
    "\n",
    "    def write_links_to_parquet(self, df, filename_suffix):\n",
    "        \"\"\"Writes the DataFrame to a parquet file with a unique timestamp.\"\"\"\n",
    "        filename = f\"/{filename_suffix}-{int(time.time())}.parquet\"\n",
    "        df.sink_parquet(self.data_path + filename)\n",
    "\n",
    "    def execute(self):\n",
    "        \"\"\"Template method to be overridden by subclasses.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement the `execute` method.\")\n",
    "\n",
    "\n",
    "class FarcasterLinksAggregator(FarcasterBaseProcessor):\n",
    "    async def execute(self):\n",
    "        logging.info(\"Aggregating links...\")\n",
    "        start = time.time()\n",
    "        latest_file = await self.get_latest_parquet_file(\"farcaster-links-0-*.parquet\")\n",
    "        links_lazy_df = self.get_links_lazy_df(latest_file)\n",
    "        mutual_links = self.get_mutual_links(links_lazy_df)\n",
    "        self.write_links_to_parquet(mutual_links, \"processed-farcaster-mutual-links\")\n",
    "        logging.info(f\"Execution time: {time.time() - start} seconds\")\n",
    "        return mutual_links\n",
    "\n",
    "    def get_mutual_links(self, links_df):\n",
    "        df_filtered = links_df.filter(\n",
    "            (pl.col(\"deleted_at\").is_null())\n",
    "            & (pl.col(\"fid\") != pl.col(\"target_fid\"))\n",
    "            & (pl.col(\"type\") == \"follow\")\n",
    "        ).select([\"fid\", \"target_fid\"])\n",
    "\n",
    "        df_sorted = df_filtered.with_columns(\n",
    "            [\n",
    "                pl.min_horizontal([\"fid\", \"target_fid\"]).alias(\"sorted_fid\"),\n",
    "                pl.max_horizontal([\"fid\", \"target_fid\"]).alias(\"sorted_target_fid\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        df_grouped = df_sorted.group_by([\"sorted_fid\", \"sorted_target_fid\"]).agg(\n",
    "            pl.count().alias(\"count\")\n",
    "        )\n",
    "\n",
    "        return df_grouped.filter(pl.col(\"count\") == 2).select(\n",
    "            [\n",
    "                pl.col(\"sorted_fid\").alias(\"fid\"),\n",
    "                pl.col(\"sorted_target_fid\").alias(\"target_fid\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "class FarcasterUndirectedLinksBuilder(FarcasterBaseProcessor):\n",
    "    async def execute(self):\n",
    "        logging.info(\"Building undirected links...\")\n",
    "        start = time.time()\n",
    "        latest_file = await self.get_latest_parquet_file(\n",
    "            \"processed-farcaster-mutual-links-*.parquet\"\n",
    "        )\n",
    "        links_lazy_df = self.get_links_lazy_df(latest_file)\n",
    "        undirected_links = self.get_undirected_links(links_lazy_df)\n",
    "        self.write_links_to_parquet(\n",
    "            undirected_links, \"processed-farcaster-undirected-connections\"\n",
    "        )\n",
    "        logging.info(f\"Execution time: {time.time() - start} seconds\")\n",
    "        return undirected_links\n",
    "\n",
    "    def get_undirected_links(self, links_df):\n",
    "        fids = links_df.select(\"fid\").unique()\n",
    "        target_fids = (\n",
    "            links_df.select(\"target_fid\").unique().rename({\"target_fid\": \"fid\"})\n",
    "        )\n",
    "        all_fids = (\n",
    "            pl.concat([fids, target_fids]).unique().collect()\n",
    "        )  # test streaming mode\n",
    "\n",
    "        # Use the collected DataFrame's shape to get the height\n",
    "        mutual_reindex = all_fids.with_columns(\n",
    "            pl.arange(0, all_fids.shape[0]).alias(\"index\")\n",
    "        )\n",
    "\n",
    "        mutual_links_with_index = links_df.join(\n",
    "            mutual_reindex.select(\n",
    "                [pl.col(\"fid\"), pl.col(\"index\").alias(\"fid_index\")]\n",
    "            ).lazy(),\n",
    "            on=\"fid\",\n",
    "            how=\"left\",\n",
    "        ).join(\n",
    "            mutual_reindex.select(\n",
    "                [pl.col(\"fid\"), pl.col(\"index\").alias(\"target_fid_index\")]\n",
    "            ).lazy(),\n",
    "            left_on=\"target_fid\",\n",
    "            right_on=\"fid\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "\n",
    "        df_reversed = mutual_links_with_index.select(\n",
    "            [\n",
    "                pl.col(\"target_fid\").alias(\"fid\"),\n",
    "                pl.col(\"fid\").alias(\"target_fid\"),\n",
    "                pl.col(\"target_fid_index\").alias(\"fid_index\"),\n",
    "                pl.col(\"fid_index\").alias(\"target_fid_index\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        order = [\"fid\", \"target_fid\", \"fid_index\", \"target_fid_index\"]\n",
    "        mutual_links_with_index_concatenated = pl.concat(\n",
    "            [mutual_links_with_index.select(order), df_reversed.select(order)]\n",
    "        )\n",
    "\n",
    "        # mutual_links_with_index_concatenated = mutual_links_with_index_concatenated.with_columns(\n",
    "        #     (pl.col(\"fid_index\").cast(pl.Utf8) + \" \" + pl.col(\"target_fid_index\").cast(pl.Utf8)).alias(\"connection\")\n",
    "        # )\n",
    "\n",
    "        labels_df = pl.scan_parquet(\n",
    "            f\"/{self.persisted_data_path}/labels.parquet\"\n",
    "        )\n",
    "\n",
    "        return mutual_links_with_index_concatenated.join(\n",
    "            labels_df, how=\"left\", on=\"fid\"\n",
    "        ).select(\"fid\", \"fid_index\", \"target_fid_index\", \"bot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/v9m0s0cn02j1r54h8qh_tf200000gn/T/ipykernel_24082/1797128931.py:64: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  pl.count().alias(\"count\")\n"
     ]
    }
   ],
   "source": [
    "links_aggregator = FarcasterLinksAggregator()\n",
    "await links_aggregator.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undirected_links_builder = FarcasterUndirectedLinksBuilder()\n",
    "await undirected_links_builder.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (51_754_872, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>fid</th><th>fid_index</th><th>target_fid_index</th><th>bot</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>bool</td></tr></thead><tbody><tr><td>305835</td><td>250996</td><td>295895</td><td>null</td></tr><tr><td>19339</td><td>193983</td><td>165313</td><td>null</td></tr><tr><td>409969</td><td>343448</td><td>133977</td><td>null</td></tr><tr><td>343904</td><td>66298</td><td>15087</td><td>null</td></tr><tr><td>303580</td><td>111181</td><td>342016</td><td>null</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>414665</td><td>58445</td><td>190169</td><td>null</td></tr><tr><td>500400</td><td>206948</td><td>10571</td><td>null</td></tr><tr><td>412579</td><td>187304</td><td>274188</td><td>null</td></tr><tr><td>509675</td><td>282444</td><td>6027</td><td>null</td></tr><tr><td>846645</td><td>346518</td><td>276091</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (51_754_872, 4)\n",
       "┌────────┬───────────┬──────────────────┬──────┐\n",
       "│ fid    ┆ fid_index ┆ target_fid_index ┆ bot  │\n",
       "│ ---    ┆ ---       ┆ ---              ┆ ---  │\n",
       "│ i64    ┆ i64       ┆ i64              ┆ bool │\n",
       "╞════════╪═══════════╪══════════════════╪══════╡\n",
       "│ 305835 ┆ 250996    ┆ 295895           ┆ null │\n",
       "│ 19339  ┆ 193983    ┆ 165313           ┆ null │\n",
       "│ 409969 ┆ 343448    ┆ 133977           ┆ null │\n",
       "│ 343904 ┆ 66298     ┆ 15087            ┆ null │\n",
       "│ 303580 ┆ 111181    ┆ 342016           ┆ null │\n",
       "│ …      ┆ …         ┆ …                ┆ …    │\n",
       "│ 414665 ┆ 58445     ┆ 190169           ┆ null │\n",
       "│ 500400 ┆ 206948    ┆ 10571            ┆ null │\n",
       "│ 412579 ┆ 187304    ┆ 274188           ┆ null │\n",
       "│ 509675 ┆ 282444    ┆ 6027             ┆ null │\n",
       "│ 846645 ┆ 346518    ┆ 276091           ┆ null │\n",
       "└────────┴───────────┴──────────────────┴──────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_farcaster_undirected_connections = pl.read_parquet(f\"{DATA_PATH}/raw/processed-farcaster-undirected-connections-1734540373.parquet\")\n",
    "processed_farcaster_undirected_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from typing import Set, Dict, Tuple, List\n",
    "import polars as pl\n",
    "import time\n",
    "import asyncio\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "\n",
    "class SybilScar:\n",
    "    def __init__(self):\n",
    "        self.network_map = defaultdict(list)\n",
    "        self.weighted_graph = 0\n",
    "        self.prior = None\n",
    "        self.post = None\n",
    "        self.post_pre = None\n",
    "        self.theta_pos = 0.6\n",
    "        self.theta_neg = 0.4\n",
    "        self.theta_unl = 0.5\n",
    "        self.weight = 0.6\n",
    "        self.max_iter = 10\n",
    "        self.N = 0\n",
    "        self.ordering_array = []\n",
    "        self.semaphore = asyncio.Semaphore(4)\n",
    "\n",
    "    def add_edge(self, node1, node2, w):\n",
    "        if node1 != node2:  # Avoid self-loops\n",
    "            self.network_map[node1].append((node2, w))\n",
    "\n",
    "    # Refactored to read from in-memory connections data\n",
    "    def read_network(self, connections):\n",
    "        for node1, node2 in connections:\n",
    "            self.add_edge(node1, node2, self.weight - 0.5)\n",
    "\n",
    "        self.N = len(self.network_map)\n",
    "        self.post = np.zeros(self.N)\n",
    "        self.post_pre = np.zeros(self.N)\n",
    "        self.prior = np.zeros(self.N)\n",
    "\n",
    "    # Refactored to read from in-memory sybil and benigns sets\n",
    "    def read_prior(self, train_sybils, train_benigns):\n",
    "        self.prior.fill(self.theta_unl - 0.5)\n",
    "\n",
    "        for benign in train_benigns:\n",
    "            self.prior[benign] = self.theta_pos - 0.5\n",
    "\n",
    "        for sybil in train_sybils:\n",
    "            self.prior[sybil] = self.theta_neg - 0.5\n",
    "\n",
    "    ## Write final posterior probabilities of nodes to the output file\n",
    "    ## The final posterior probability is changed from p (in the residual form) to p + 0.5.\n",
    "    def get_posterior(self, post_file):\n",
    "        # with open(post_file, 'w') as f:\n",
    "        #     for i in range(self.N):\n",
    "        #         f.write(f\"{i} {self.post[i] + 0.5:.10f}\\n\")\n",
    "\n",
    "        data = [\n",
    "            {\"fid_index\": i, \"posterior\": self.post[i] + 0.5} for i in range(self.N)\n",
    "        ]\n",
    "        df_lazy = pl.LazyFrame(data)\n",
    "        return df_lazy\n",
    "\n",
    "    async def lbp_thread(self, start, end):\n",
    "        async with self.semaphore:\n",
    "            for index in range(start, end):\n",
    "                node = self.ordering_array[index]\n",
    "                # update the the post for node\n",
    "                for neighbor, weight in self.network_map[node]:\n",
    "                    self.post[node] += 2 * self.post_pre[neighbor] * weight\n",
    "                self.post[node] += self.prior[node]\n",
    "                self.post[node] = max(min(self.post[node], 0.5), -0.5)\n",
    "\n",
    "    # Async version of the LBP algorithm\n",
    "    async def lbp_async(self):\n",
    "        self.ordering_array = list(range(self.N))\n",
    "\n",
    "        # initialize posts\n",
    "        np.copyto(self.post, self.prior)\n",
    "        iter_count = 1\n",
    "\n",
    "        while iter_count <= self.max_iter:\n",
    "            random.shuffle(self.ordering_array)\n",
    "            np.copyto(self.post_pre, self.post)\n",
    "\n",
    "            tasks = []\n",
    "            num_nodes = int(\n",
    "                np.ceil(self.N / self.semaphore._value)\n",
    "            )  # Divide tasks by semaphore limit\n",
    "            for current_thread in range(self.semaphore._value):\n",
    "                start = current_thread * num_nodes\n",
    "                end = min(start + num_nodes, self.N)\n",
    "                task = asyncio.create_task(self.lbp_thread(start, end))\n",
    "                tasks.append(task)\n",
    "\n",
    "            await asyncio.gather(*tasks)\n",
    "            iter_count += 1\n",
    "\n",
    "\n",
    "class SybilScarExecutor:\n",
    "    def __init__(self):\n",
    "        self.data_path = DATA_PATH\n",
    "        self.sybil_scar = SybilScar()\n",
    "        \n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load data from the Parquet file and process connections, sybils, and benigns.\"\"\"\n",
    "\n",
    "        connections_df = processed_farcaster_undirected_connections\n",
    "        self.connections = ((row[0], row[1]) for row in connections_df[[\"fid_index\", \"target_fid_index\"]].iter_rows())\n",
    "\n",
    "        sybils_df = (\n",
    "            connections_df.filter(\n",
    "                pl.col(\"fid\").is_in(train_sybilscar.filter(pl.col(\"bot\"))[\"fid\"])\n",
    "            )[\"fid_index\"]\n",
    "            .unique()\n",
    "        )\n",
    "        self.sybils = (s for s in sybils_df.to_list())\n",
    "\n",
    "        benigns_df = (\n",
    "            connections_df.filter(\n",
    "                pl.col(\"fid\").is_in(train_sybilscar.filter(~pl.col(\"bot\"))[\"fid\"])\n",
    "            )[\"fid_index\"]\n",
    "            .unique()\n",
    "        )\n",
    "        self.benigns = (b for b in benigns_df.to_list())\n",
    "\n",
    "    async def arun_sybil_scar(self):\n",
    "        \"\"\"Execute the SybilScar algorithm asynchronously on the loaded data.\"\"\"\n",
    "        self.sybil_scar.read_network(self.connections)\n",
    "        self.sybil_scar.read_prior(self.sybils, self.benigns)\n",
    "        await self.sybil_scar.lbp_async()\n",
    "\n",
    "    def save_results(self, output_file: str):\n",
    "        \"\"\"Write the SybilScar post results to a file.\"\"\"\n",
    "        posterior_df = self.sybil_scar.get_posterior(output_file)\n",
    "        posterior_df.sink_parquet(output_file)\n",
    "\n",
    "    async def execute(self):\n",
    "        \"\"\"Load data, run the algorithm, and save the results.\"\"\"\n",
    "        logging.info(\"Running SybilScar...\")\n",
    "        start = time.time()\n",
    "\n",
    "        self.load_data()\n",
    "\n",
    "        logging.info(\"Data loaded. Running SybilScar algorithm...\")\n",
    "        await self.arun_sybil_scar()\n",
    "\n",
    "        logging.info(\"SybilScar algorithm executed. Saving results...\")\n",
    "        self.save_results(\n",
    "            self.data_path + \"/sybil_scar_results.parquet\"\n",
    "        )\n",
    "        end = time.time()\n",
    "\n",
    "        logging.info(f\"SybilScar execution time: {end - start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sybilscar_executor = SybilScarExecutor()\n",
    "await sybilscar_executor.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (374_334, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>fid_index</th><th>posterior</th><th>fid</th></tr><tr><td>i64</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>288133</td><td>0.0</td><td>828590</td></tr><tr><td>277001</td><td>0.0</td><td>689601</td></tr><tr><td>315676</td><td>0.0</td><td>277661</td></tr><tr><td>105801</td><td>0.5</td><td>784876</td></tr><tr><td>277135</td><td>0.0</td><td>374229</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>291872</td><td>0.0</td><td>813266</td></tr><tr><td>144154</td><td>0.0</td><td>716396</td></tr><tr><td>321231</td><td>0.0</td><td>861510</td></tr><tr><td>288740</td><td>0.0</td><td>373640</td></tr><tr><td>248883</td><td>0.0</td><td>638508</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (374_334, 3)\n",
       "┌───────────┬───────────┬────────┐\n",
       "│ fid_index ┆ posterior ┆ fid    │\n",
       "│ ---       ┆ ---       ┆ ---    │\n",
       "│ i64       ┆ f64       ┆ i64    │\n",
       "╞═══════════╪═══════════╪════════╡\n",
       "│ 288133    ┆ 0.0       ┆ 828590 │\n",
       "│ 277001    ┆ 0.0       ┆ 689601 │\n",
       "│ 315676    ┆ 0.0       ┆ 277661 │\n",
       "│ 105801    ┆ 0.5       ┆ 784876 │\n",
       "│ 277135    ┆ 0.0       ┆ 374229 │\n",
       "│ …         ┆ …         ┆ …      │\n",
       "│ 291872    ┆ 0.0       ┆ 813266 │\n",
       "│ 144154    ┆ 0.0       ┆ 716396 │\n",
       "│ 321231    ┆ 0.0       ┆ 861510 │\n",
       "│ 288740    ┆ 0.0       ┆ 373640 │\n",
       "│ 248883    ┆ 0.0       ┆ 638508 │\n",
       "└───────────┴───────────┴────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sybilscar_results = pl.read_parquet(f\"{DATA_PATH}/sybil_scar_results.parquet\")\n",
    "processed_farcaster_undirected_connections = processed_farcaster_undirected_connections.drop(\"bot\").join(\n",
    "    labels, how=\"left\", on=\"fid\", coalesce=True\n",
    ")[[\"fid\", \"fid_index\", \"target_fid_index\", \"bot\"]]\n",
    "processed_farcaster_undirected_connections\n",
    "index_to_fid = processed_farcaster_undirected_connections.group_by(\"fid_index\").agg(pl.col(\"fid\").last())\n",
    "index_to_fid\n",
    "\n",
    "sybilscar_results = sybilscar_results.join(index_to_fid,on=\"fid_index\",coalesce=True)\n",
    "sybilscar_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4_420, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>fid</th><th>bot</th><th>sybilscar_proba</th></tr><tr><td>i64</td><td>bool</td><td>f64</td></tr></thead><tbody><tr><td>11</td><td>false</td><td>0.0</td></tr><tr><td>52</td><td>false</td><td>0.0</td></tr><tr><td>63</td><td>false</td><td>0.0</td></tr><tr><td>64</td><td>false</td><td>0.0</td></tr><tr><td>81</td><td>false</td><td>0.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>280179</td><td>true</td><td>1.0</td></tr><tr><td>423036</td><td>true</td><td>1.0</td></tr><tr><td>327500</td><td>true</td><td>1.0</td></tr><tr><td>428200</td><td>true</td><td>1.0</td></tr><tr><td>278549</td><td>true</td><td>1.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4_420, 3)\n",
       "┌────────┬───────┬─────────────────┐\n",
       "│ fid    ┆ bot   ┆ sybilscar_proba │\n",
       "│ ---    ┆ ---   ┆ ---             │\n",
       "│ i64    ┆ bool  ┆ f64             │\n",
       "╞════════╪═══════╪═════════════════╡\n",
       "│ 11     ┆ false ┆ 0.0             │\n",
       "│ 52     ┆ false ┆ 0.0             │\n",
       "│ 63     ┆ false ┆ 0.0             │\n",
       "│ 64     ┆ false ┆ 0.0             │\n",
       "│ 81     ┆ false ┆ 0.0             │\n",
       "│ …      ┆ …     ┆ …               │\n",
       "│ 280179 ┆ true  ┆ 1.0             │\n",
       "│ 423036 ┆ true  ┆ 1.0             │\n",
       "│ 327500 ┆ true  ┆ 1.0             │\n",
       "│ 428200 ┆ true  ┆ 1.0             │\n",
       "│ 278549 ┆ true  ┆ 1.0             │\n",
       "└────────┴───────┴─────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sybilscar auc: 0.9545484093947662\n"
     ]
    }
   ],
   "source": [
    "sybilscar_predictions = test_sybilscar.join(sybilscar_results[[\"fid\",\"posterior\"]],how=\"left\",on=\"fid\",coalesce=True)\n",
    "sybilscar_predictions = sybilscar_predictions.with_columns((1-pl.col(\"posterior\")).alias(\"sybilscar_proba\")).drop(\"posterior\")\n",
    "# predictions = predictions.with_columns(pl.Series(\"ml_proba\",ml_output).alias(\"ml_proba\"))\n",
    "# predictions = predictions.with_columns(pl.Series(\"ml_proba\",ml_output).alias(\"ensemble_proba\"))\n",
    "sybilscar_predictions = sybilscar_predictions.filter(pl.col(\"sybilscar_proba\").is_not_null())\n",
    "display(sybilscar_predictions)\n",
    "\n",
    "sybilscar_auc = roc_auc_score(\n",
    "  sybilscar_predictions[\"bot\"].cast(pl.Int8).to_numpy(),\n",
    "  sybilscar_predictions[f\"sybilscar_proba\"]\n",
    ")\n",
    "\n",
    "print(\"sybilscar auc:\",sybilscar_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1432148184970624"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sybilscar_results[\"posterior\"].sum() / len(sybilscar_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_443, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>fid</th><th>bot</th><th>ml_proba</th><th>sybilscar_proba</th><th>ensemble_proba</th></tr><tr><td>i64</td><td>bool</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>11</td><td>false</td><td>0.05556</td><td>0.0</td><td>0.02778</td></tr><tr><td>52</td><td>false</td><td>0.067287</td><td>0.0</td><td>0.033643</td></tr><tr><td>55</td><td>false</td><td>0.057609</td><td>null</td><td>0.057609</td></tr><tr><td>63</td><td>false</td><td>0.091361</td><td>0.0</td><td>0.04568</td></tr><tr><td>64</td><td>false</td><td>0.053966</td><td>0.0</td><td>0.026983</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>351522</td><td>true</td><td>0.985655</td><td>1.0</td><td>0.992827</td></tr><tr><td>421493</td><td>true</td><td>0.949381</td><td>0.0</td><td>0.474691</td></tr><tr><td>287794</td><td>true</td><td>0.985682</td><td>1.0</td><td>0.992841</td></tr><tr><td>423036</td><td>true</td><td>0.98561</td><td>1.0</td><td>0.992805</td></tr><tr><td>327500</td><td>true</td><td>0.98557</td><td>1.0</td><td>0.992785</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_443, 5)\n",
       "┌────────┬───────┬──────────┬─────────────────┬────────────────┐\n",
       "│ fid    ┆ bot   ┆ ml_proba ┆ sybilscar_proba ┆ ensemble_proba │\n",
       "│ ---    ┆ ---   ┆ ---      ┆ ---             ┆ ---            │\n",
       "│ i64    ┆ bool  ┆ f64      ┆ f64             ┆ f64            │\n",
       "╞════════╪═══════╪══════════╪═════════════════╪════════════════╡\n",
       "│ 11     ┆ false ┆ 0.05556  ┆ 0.0             ┆ 0.02778        │\n",
       "│ 52     ┆ false ┆ 0.067287 ┆ 0.0             ┆ 0.033643       │\n",
       "│ 55     ┆ false ┆ 0.057609 ┆ null            ┆ 0.057609       │\n",
       "│ 63     ┆ false ┆ 0.091361 ┆ 0.0             ┆ 0.04568        │\n",
       "│ 64     ┆ false ┆ 0.053966 ┆ 0.0             ┆ 0.026983       │\n",
       "│ …      ┆ …     ┆ …        ┆ …               ┆ …              │\n",
       "│ 351522 ┆ true  ┆ 0.985655 ┆ 1.0             ┆ 0.992827       │\n",
       "│ 421493 ┆ true  ┆ 0.949381 ┆ 0.0             ┆ 0.474691       │\n",
       "│ 287794 ┆ true  ┆ 0.985682 ┆ 1.0             ┆ 0.992841       │\n",
       "│ 423036 ┆ true  ┆ 0.98561  ┆ 1.0             ┆ 0.992805       │\n",
       "│ 327500 ┆ true  ┆ 0.98557  ┆ 1.0             ┆ 0.992785       │\n",
       "└────────┴───────┴──────────┴─────────────────┴────────────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble of sybilscar and ml predictions\n",
    "\n",
    "ensemble_predictions = ml_predictions.join(sybilscar_predictions[[\"fid\",\"sybilscar_proba\"]],how=\"left\",on=\"fid\",coalesce=True)\n",
    "ensemble_predictions = ensemble_predictions.with_columns(\n",
    "  pl.when(pl.col('sybilscar_proba').is_null() & pl.col('ml_proba').is_null())\n",
    "    .then(None)\n",
    "    .when(pl.col('ml_proba').is_null())\n",
    "    .then(pl.col('sybilscar_proba'))\n",
    "    .when(pl.col('sybilscar_proba').is_null())\n",
    "    .then(pl.col('ml_proba'))\n",
    "    .otherwise((pl.col('sybilscar_proba') + pl.col('ml_proba')) / 2)\n",
    "    .alias('ensemble_proba')\n",
    ")\n",
    "ensemble_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble auc: 0.9922682813227759\n"
     ]
    }
   ],
   "source": [
    "ensemble_auc = roc_auc_score(\n",
    "  ensemble_predictions[\"bot\"].cast(pl.Int8).to_numpy(),\n",
    "  ensemble_predictions[f\"ensemble_proba\"]\n",
    ")\n",
    "\n",
    "print(\"ensemble auc:\",ensemble_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "farcaster-social-graph-notebooks",
   "language": "python",
   "name": "farcaster-social-graph-notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
